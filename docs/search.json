[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Himalayas Project",
    "section": "",
    "text": "Introduction\n1.1 Provide an introduction that explains the problem statement you are addressing. Why should I be interested in this?\nThe dataset we are analyzing is\n1.2 Provide a short explanation of how you plan to address this problem statement (the data used and the methodology employed)\n1.3 Discuss your current proposed approach/analytic technique you think will address (fully or partially) this problem.\n1.4 Explain how your analysis will help the consumer of your analysis\n\n\nPackages required\n\nlibrary(ggplot2) # visualization of data through graphs \nlibrary(tidyverse) # i forgot\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ lubridate 1.9.4     ✔ tibble    3.2.1\n✔ purrr     1.0.4     ✔ tidyr     1.3.1\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\n\nData preparation\n\nexped_tidy &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-01-21/exped_tidy.csv')\n\nRows: 882 Columns: 69\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (22): EXPID, PEAKID, SEASON_FACTOR, HOST_FACTOR, ROUTE1, ROUTE2, NATION...\ndbl  (17): YEAR, SEASON, HOST, SMTDAYS, TOTDAYS, TERMREASON, HIGHPOINT, CAMP...\nlgl  (27): ROUTE3, ROUTE4, SUCCESS1, SUCCESS2, SUCCESS3, SUCCESS4, ASCENT3, ...\ndate  (3): BCDATE, SMTDATE, TERMDATE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npeaks_tidy &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/main/data/2025/2025-01-21/peaks_tidy.csv')\n\nRows: 480 Columns: 29\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (14): PEAKID, PKNAME, PKNAME2, LOCATION, HIMAL_FACTOR, REGION_FACTOR, RE...\ndbl (12): HEIGHTM, HEIGHTF, HIMAL, REGION, TREKYEAR, PHOST, PSTATUS, PEAKMEM...\nlgl  (3): OPEN, UNLISTED, TREKKING\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n3.1 Original source where the data was obtained is cited and, if possible, hyperlinked.\nThe data used for this project was obtained through a github repo - the original dataset is from the Himalayan Database. This database covers data from expedition archives of a well known journalist, Elizabeth Hawley.\n3.2 Source data is thoroughly explained (i.e. what was the original purpose of the data, when was it collected, how many variables did the original have, explain any peculiarities of the source data such as how missing values are recorded, etc).\n3.3 Data importing and cleaning steps are explained in the text (tell me why you are doing the data cleaning activities that you perform) and follow a logical process.\n3.4 Once your data is clean, show what the final data set looks like. However, do not print more than 20 rows of your data to the screen; rather, show me the data in a condensed form (i.e. using enhanced print for tibbles, head/tail commands, etc).\n3.5 Provide summary information about the variables of concern in your cleaned data set. provide me with a consolidated explanation, either with a table that provides summary info for each variable or a nicely written summary paragraph with inline code.\n\n\nExploratory Data Analysis\n\nannapuerna &lt;- subset(exped_tidy,\n                     select = c(PEAKID, TOTMEMBERS, MDEATHS, NOHIRED),\n                     MDEATHS &gt; 0 )\n\nannapuerna &lt;- annapuerna |&gt; select (PEAKID, MDEATHS, TOTMEMBERS, NOHIRED) |&gt;  mutate(rate = MDEATHS/TOTMEMBERS)\n\nggplot(annapuerna, aes(x = PEAKID, y = rate, fill = NOHIRED)) +\n  geom_col()\n\n\n\n\n\n\n\n\nWhich mountain range (HIMAL_FACTOR) has the highest average peak height (HEIGHTM)?\n\nslice_max(subset(peaks_tidy, select = c(HIMAL_FACTOR, HEIGHTM)), order_by = HEIGHTM)\n\n# A tibble: 1 × 2\n  HIMAL_FACTOR HEIGHTM\n  &lt;chr&gt;          &lt;dbl&gt;\n1 Khumbu          8849\n\n\nThe mountain ranges that most people climbed\n\nggplot(peaks_tidy, aes(x = HIMAL_FACTOR, fill = PSTATUS_FACTOR)) +\n  geom_bar(position = \"dodge\")+\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  labs(\n    x = \"Mountain range\") +\n  theme(legend.position = \"top\", legend) +\n  scale_fill_discrete(labels = c(\"Climbed\", \"Unclimbed\"),\n                    name = \"Climbing status\")"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html#introduction",
    "href": "index.html#introduction",
    "title": "HimalayasProject",
    "section": "",
    "text": "1.1 Provide an introduction that explains the problem statement you are addressing. Why should I be interested in this?\nClimbing the Himalayan mountains is no easy feat. We wish to provide a guide for future explorers based on analysis from past data to make the travel experience better lol.\n1.2 Provide a short explanation of how you plan to address this problem statement (the data used and the methodology employed)\n1.3 Discuss your current proposed approach/analytic technique you think will address (fully or partially) this problem.\n1.4 Explain how your analysis will help the consumer of your analysis"
  },
  {
    "objectID": "index.html#packages-required",
    "href": "index.html#packages-required",
    "title": "HimalayasProject",
    "section": "",
    "text": "library(ggplot2) # visualization of data through graphs library(janitor) # clean data library(tidyverse) # i forgot"
  },
  {
    "objectID": "index.html#data-preparation",
    "href": "index.html#data-preparation",
    "title": "HimalayasProject",
    "section": "",
    "text": "3.1 Original source where the data was obtained is cited and, if possible, hyperlinked.\nThe data used for this project was obtained through a github repo - the original dataset is from the Himalayan Database. This database covers data from expedition archives of a well known journalist, Elizabeth Hawley. https://www.himalayandatabase.com/index.html\n3.2 Source data is thoroughly explained (i.e. what was the original purpose of the data, when was it collected, how many variables did the original have, explain any peculiarities of the source data such as how missing values are recorded, etc).\n3.3 Data importing and cleaning steps are explained in the text (tell me why you are doing the data cleaning activities that you perform) and follow a logical process.\n3.4 Once your data is clean, show what the final data set looks like. However, do not print more than 20 rows of your data to the screen; rather, show me the data in a condensed form (i.e. using enhanced print for tibbles, head/tail commands, etc).\n3.5 Provide summary information about the variables of concern in your cleaned data set. provide me with a consolidated explanation, either with a table that provides summary info for each variable or a nicely written summary paragraph with inline code."
  }
]